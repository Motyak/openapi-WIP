
Spotify Web API https://developer.spotify.com/documentation/web-api

Both official and Fixed/Improved spotify web api openapi yml file https://github.com/sonallux/spotify-web-api

openapi generator https://github.com/OpenAPITools/openapi-generator

https://www.baeldung.com/spring-boot-rest-client-swagger-codegen

# tools built around OpenAPI/Swagger specifications and/or curl commands

## Postman

sophisticated graphical http client, with variables/context/scripting mechanisms

can import:
- postman collection
- curl command
- openapi/swagger yml file

can export to:
- curl command
- postman collection

## Mockoon

allows to launch a configurable mock server based on a swagger/openapi yml file

## Swagger codegen / openapi-generator

allows to generate API client source files based on a swagger/openapi yml file, in a lot of different languages.
We may only need the models (which are basically the rest api json input/output).

## JMeter

allows to define and perform load/performance tests on an api (based on a curl request ++)


# openapi generators to test

https://openapi-generator.tech/docs/generators

- bash
	- on va pas y trouver une utilité dans notre cas, autant importer le yml dans Postman si c'est pour faire des tests manuels, utilisation rapide
- jmeter
	- intéressant, à voir (mais pas priorité)
- groovy
	- servira pour le POC
- python
	- servira pour le POC
- c++ (personal)
	- de la merde, enlevez ça de ma vue (le code, pas le langage je précise)
- perl
	- franchement le code généré est bon, on peut y trouver une utilité car l'avantage c'est que c'est plus facile de trouver un interpréteur perl que python sur une machine linux. Après c'est plus dur à prendre en main (par rapport à python). Je verrais si j'y trouve un intérêt personnel, mais ça fera pas partie du POC.

# structure repository publique

Ca fait du sens de faire un repo par langage, et tous appartiendraient à un même projet.

- groovy
	- COMMON (le code générique pour l'envoi/réception de requêtes HTTP, sérialisation/désérialisation des données JSON, gestion des erreurs HTTP, ...)
		- impl-groovyx-net-http-groovy-json (implémente l'interface du common, méthodes pour faire du http sync/async, parsing json vers model, etc..)
		- impl-java-net-http-groovy-json (mon implémentation actuelle pour le coup)
	- cms
		- doc (contient le .yml, + éventuellement de la doc auto-généré en markdown, ...)
		- model
		- utils (classe qui utilise le code COMMON + model/\* pour faire des fonctions réutilisables, qui font abstraction du HTTP/JSON/..., ) N'utilise que les classes abstraites définies dans la partie COMMON (on choisir l'implémentation dans le main, ça ne doit pas avoir d'incidence sur le bon fonctionnement des fonctions utils). Un exemple de fonction util pour le CMS serait celle qui va 1) attendre que l'environnement soit prêt 2) générer un plan 3) attendre que le plan soit en pending 4) executer le plan.
	- token-svc
- python
- jmeter
	- cms
		- doc
		- <.jmx .csv files>


On va seulement générer les models, le reste ça sera fait à la main (on peut s'inspirer de ce qui est généré également).

L'idée ça serait que n'importe qui puisse définir ses fonctions utils en faisant abstraction de la couche HTTP/JSON/..., simplement à partir de la doc (yml) et des classes disponibles (COMMON/ et models/).

Ecrire des tests unitaires FONCTIONNELS en spock, qui vont envoyer des vrais requêtes HTTP, sauf qu'on override le base path pour mettre 127.0.0.1 et port mockoon.

# TODO:

## faire un repo github publique avec mes notes et code généré

## Synchronisation contrat service

Quelle version du swagger file doit on avoir pour être "synchronisé" ?
- La même que celle utilisée par le service déployé sur notre cluster ? (du coup ça dépend du cluster)
- Le contrat qu'on trouve sur le repo du microservice, branche master ? branche develop ?
- Pouvoir choisir ? (à mon avis idée de merde, mais au moins configurable avec choix par défaut)

## Lancer openapi-generator sur une pipeline jenkins

- comment l'installer, quelle version

## POC

Commencer une première version du repo (repo privé pour l'instant), faire aussi un cas d'utilisation concret (par exemple une pipeline jenkins, qui importe en tant que shared library, ou encore un script python à executer en local qui utilise un submodule git -- l'execution va donc s'assurer que le submodule soit bien à jour puis lancer le script).

