# coding: utf-8

"""
    Spotify Web API with fixes and improvements from sonallux

    You can use Spotify's Web API to discover music and podcasts, manage your Spotify library, control audio playback, and much more. Browse our available Web API endpoints using the sidebar at left, or via the navigation bar on top of this page on smaller screens.  In order to make successful Web API requests your app will need a valid access token. One can be obtained through <a href=\"https://developer.spotify.com/documentation/general/guides/authorization-guide/\">OAuth 2.0</a>.  The base URI for all Web API requests is `https://api.spotify.com/v1`.  Need help? See our <a href=\"https://developer.spotify.com/documentation/web-api/guides/\">Web API guides</a> for more information, or visit the <a href=\"https://community.spotify.com/t5/Spotify-for-Developers/bd-p/Spotify_Developer\">Spotify for Developers community forum</a> to ask questions and connect with other developers. 

    The version of the OpenAPI document: 2023.8.30
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import List, Optional
from pydantic import BaseModel, Field, conlist
from openapi_client.models.audio_analysis_object_meta import AudioAnalysisObjectMeta
from openapi_client.models.audio_analysis_object_track import AudioAnalysisObjectTrack
from openapi_client.models.section_object import SectionObject
from openapi_client.models.segment_object import SegmentObject
from openapi_client.models.time_interval_object import TimeIntervalObject

class AudioAnalysisObject(BaseModel):
    """
    AudioAnalysisObject
    """
    meta: Optional[AudioAnalysisObjectMeta] = None
    track: Optional[AudioAnalysisObjectTrack] = None
    bars: Optional[conlist(TimeIntervalObject)] = Field(None, description="The time intervals of the bars throughout the track. A bar (or measure) is a segment of time defined as a given number of beats.")
    beats: Optional[conlist(TimeIntervalObject)] = Field(None, description="The time intervals of beats throughout the track. A beat is the basic time unit of a piece of music; for example, each tick of a metronome. Beats are typically multiples of tatums.")
    sections: Optional[conlist(SectionObject)] = Field(None, description="Sections are defined by large variations in rhythm or timbre, e.g. chorus, verse, bridge, guitar solo, etc. Each section contains its own descriptions of tempo, key, mode, time_signature, and loudness.")
    segments: Optional[conlist(SegmentObject)] = Field(None, description="Each segment contains a roughly conisistent sound throughout its duration.")
    tatums: Optional[conlist(TimeIntervalObject)] = Field(None, description="A tatum represents the lowest regular pulse train that a listener intuitively infers from the timing of perceived musical events (segments).")
    __properties = ["meta", "track", "bars", "beats", "sections", "segments", "tatums"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> AudioAnalysisObject:
        """Create an instance of AudioAnalysisObject from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self):
        """Returns the dictionary representation of the model using alias"""
        _dict = self.dict(by_alias=True,
                          exclude={
                          },
                          exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of meta
        if self.meta:
            _dict['meta'] = self.meta.to_dict()
        # override the default output from pydantic by calling `to_dict()` of track
        if self.track:
            _dict['track'] = self.track.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in bars (list)
        _items = []
        if self.bars:
            for _item in self.bars:
                if _item:
                    _items.append(_item.to_dict())
            _dict['bars'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in beats (list)
        _items = []
        if self.beats:
            for _item in self.beats:
                if _item:
                    _items.append(_item.to_dict())
            _dict['beats'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in sections (list)
        _items = []
        if self.sections:
            for _item in self.sections:
                if _item:
                    _items.append(_item.to_dict())
            _dict['sections'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in segments (list)
        _items = []
        if self.segments:
            for _item in self.segments:
                if _item:
                    _items.append(_item.to_dict())
            _dict['segments'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in tatums (list)
        _items = []
        if self.tatums:
            for _item in self.tatums:
                if _item:
                    _items.append(_item.to_dict())
            _dict['tatums'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: dict) -> AudioAnalysisObject:
        """Create an instance of AudioAnalysisObject from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return AudioAnalysisObject.parse_obj(obj)

        _obj = AudioAnalysisObject.parse_obj({
            "meta": AudioAnalysisObjectMeta.from_dict(obj.get("meta")) if obj.get("meta") is not None else None,
            "track": AudioAnalysisObjectTrack.from_dict(obj.get("track")) if obj.get("track") is not None else None,
            "bars": [TimeIntervalObject.from_dict(_item) for _item in obj.get("bars")] if obj.get("bars") is not None else None,
            "beats": [TimeIntervalObject.from_dict(_item) for _item in obj.get("beats")] if obj.get("beats") is not None else None,
            "sections": [SectionObject.from_dict(_item) for _item in obj.get("sections")] if obj.get("sections") is not None else None,
            "segments": [SegmentObject.from_dict(_item) for _item in obj.get("segments")] if obj.get("segments") is not None else None,
            "tatums": [TimeIntervalObject.from_dict(_item) for _item in obj.get("tatums")] if obj.get("tatums") is not None else None
        })
        return _obj


